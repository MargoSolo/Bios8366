{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fonnesbeck/Bios8366/blob/master/notebooks/Section3_2-Bootstrapping.ipynb)\n",
    "\n",
    "# Bootstrapping\n",
    "\n",
    "Параметрический вывод может быть ненадежным:\n",
    "\n",
    "- неточны, если нарушены параметрические допущения\n",
    "- если мы будем полагаться на асимптотические результаты, мы можем не достичь приемлемого уровня точности\n",
    "\n",
    "Параметрический вывод может быть трудным:\n",
    "- получение выборочного распределения может оказаться невозможным\n",
    "\n",
    "Альтернативой является оценка выборочного распределения статистики **эмпирически** без каких-либо предположений о форме генеральной совокупности.\n",
    "\n",
    "Начальная загрузка — это инструмент моделирования для оценки точности. Это связано с перекрестной проверкой, с которой мы столкнемся позже в курсе, когда будем говорить о настройке моделей машинного обучения.\n",
    "\n",
    "Этот подход чаще всего используется в качестве непараметрического метода для расчета стандартных ошибок и доверительных интервалов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_URL = 'https://raw.githubusercontent.com/fonnesbeck/Bios8366/master/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Jackknife\n",
    "\n",
    "A simple precursor to bootstrapping is the jackknife (Quenouille 1949), which facilitates the estimation of the bias and variance of an estimator. Recall that the bias of an estimator $\\widehat{\\theta}$ of $\\theta$ is:\n",
    "\n",
    "$$Bias(\\widehat{\\theta}) = E(\\widehat{\\theta}) - \\theta$$\n",
    "\n",
    "Consider calculating an estimate using $n-1$ values from the dataset $\\widehat{\\theta}_{(-i)}$ (that is, the $i^{th}$ value is removed). If this is repeated for each $i=1,\\ldots,n$ observation, we can average them to obtain:\n",
    "\n",
    "$$\\bar{\\theta}_{(n)} = n^{-1} \\sum_i \\widehat{\\theta}_{(-i)}$$\n",
    "\n",
    "The **jackknife bias estimate** is:\n",
    "\n",
    "$$b_{jack} = (n-1)(\\bar{\\theta}_{(n)} - \\widehat{\\theta})$$\n",
    "\n",
    "It can be shown that $b_{jk}$ estimates the bias up to order $O(n^{-2})$.\n",
    "\n",
    "Thus, a bias-corrected estimator is:\n",
    "\n",
    "$$\\widehat{\\theta}_{jack} = \\widehat{\\theta} - b_{jack}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jackknife_bias(data, func, **kwargs):\n",
    "    theta_hat = func(data, **kwargs)\n",
    "    n = data.shape[0]\n",
    "    idx = np.arange(n)\n",
    "    theta_jack = sum(func(data[idx!=i], **kwargs) for i in range(n))/n\n",
    "    return (n-1) * (theta_jack - theta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(0, 2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8072323532892591"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.82071996604174"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(x) - jackknife_bias(x, np.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of expressing $\\widehat{\\theta}_{jack}$ is:\n",
    "\n",
    "$$\\widehat{\\theta}_{jack} = (n^{-1}) \\sum_i  \\widetilde{\\theta}_i$$\n",
    "\n",
    "where $\\widetilde{\\theta}_i$ are known as **pseudovalues** and are defined as:\n",
    "\n",
    "$$\\widetilde{\\theta}_i = n \\widehat{\\theta} - (n-1) \\widehat{\\theta}_{(-i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jackknife(data, func, **kwargs):\n",
    "    theta_hat = func(data, **kwargs)\n",
    "    n = data.shape[0]\n",
    "    idx = np.arange(n)\n",
    "    return sum(n*theta_hat - (n-1)*func(data[idx!=i], **kwargs) for i in range(n))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8207199660417088"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jackknife(x, np.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondingly, the **jackknife variance estimate** of the estimator $\\widehat{\\theta}$ is:\n",
    "\n",
    "$$v_{jack} = \\frac{\\widetilde{s}^2}{n}$$\n",
    "\n",
    "where $\\widetilde{s}^2$ is the sample variance of the pseudo-values:\n",
    "\n",
    "$$\\widetilde{s}^2 = \\frac{\\sum_i (\\widetilde{\\theta}_i - n^{-1}\\sum_j \\widetilde{\\theta}_j)^2}{n-1}$$\n",
    "\n",
    "Under certain regularity conditions, $v_{jack}$ is a consistent estimator of $V(\\widehat{\\theta})$. It can be inconsistent for some statistics, such as the median, that are not smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a function that implements a jackknife variance estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bootstrap\n",
    "\n",
    "The bootstrap is a resampling method discovered by [Brad Efron](http://www.jstor.org/discover/10.2307/2958830?uid=3739568&uid=2&uid=4&uid=3739256&sid=21102342537691) that allows one to approximate the true sampling distribution of a dataset, and thereby obtain estimates of the mean and variance of some function of the distribution.\n",
    "\n",
    "In general, consider a statistic $T_n = g(X_1, \\ldots, X_n)$, which has variance $V_F(T_n)$. Note this implies that the variance is a function of the underlying $F$, which is unknown. \n",
    "\n",
    "One approach is to estimate $V_F(T_n)$ with some $V_{F_n}(T_n)$, which is a plug-in estimator of the variance. But, $V_{F_n}(T_n)$ may be difficult to compute, so we can attempt to approximate it with a **simulation estimate** $V_{boot}$. \n",
    "\n",
    "Here is the algorithm:\n",
    "\n",
    "1. Draw $X_{1}^*, \\ldots, X_{n}^* \\sim \\widehat{F}_n$\n",
    "2. For each r in R iterations: \n",
    "    Calculate statistic $T^*_{rn} = g(X^*_{r1}, \\ldots, X^*_{rn})$\n",
    "3. Calculate variance: $V_{boot} = \\frac{1}{R} \\sum_r \\left(T^*_{rn} - \\bar{T}^*_{.n} \\right)^2$\n",
    "\n",
    "Rather than finding a way of drawing $n$ points at random from $\\widehat{F}_n$, we can instead draw a sample of size $n$ **with replacement from the original data**. So, step 1 can be modified to:\n",
    "\n",
    "> 1. Draw $X_{1}^*, \\ldots, X_{n}^*$ with replacement from $X_{1}, \\ldots, X_{n}$\n",
    "\n",
    "\n",
    "These are called **bootrstrap samples**:\n",
    "\n",
    "$$S_1^* = \\{X_{11}^*, X_{12}^*, \\ldots, X_{1n}^*\\}$$\n",
    "\n",
    "We regard S as an \"estimate\" of population P\n",
    "\n",
    "> population : sample :: sample : bootstrap sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate samples with replacement in Python, there are a handful of approaches. We can use NumPy to generate random integers (`np,random.randint`), and use these to index DataFrame rows with `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "5  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  \n",
       "5     T  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    prostate_data = pd.read_table('../data/prostate.data.txt', index_col=0)\n",
    "except FileNotFoundError:\n",
    "    prostate_data = pd.read_table(DATA_URL + 'prostate.data.txt', index_col=0)\n",
    "prostate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.776529</td>\n",
       "      <td>3.539509</td>\n",
       "      <td>47</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.047319</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.997418</td>\n",
       "      <td>3.719651</td>\n",
       "      <td>63</td>\n",
       "      <td>1.619388</td>\n",
       "      <td>1</td>\n",
       "      <td>1.909542</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>2.853592</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.423108</td>\n",
       "      <td>3.657131</td>\n",
       "      <td>73</td>\n",
       "      <td>-0.579819</td>\n",
       "      <td>0</td>\n",
       "      <td>1.658228</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>2.157559</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.471966</td>\n",
       "      <td>3.974998</td>\n",
       "      <td>68</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>1</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>5.582932</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.091923</td>\n",
       "      <td>3.993603</td>\n",
       "      <td>68</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>2.656757</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45  \\\n",
       "9  -0.776529  3.539509   47 -1.386294    0 -1.386294        6      0   \n",
       "62  1.997418  3.719651   63  1.619388    1  1.909542        7     40   \n",
       "37  1.423108  3.657131   73 -0.579819    0  1.658228        8     15   \n",
       "97  3.471966  3.974998   68  0.438255    1  2.904165        7     20   \n",
       "51  1.091923  3.993603   68 -1.386294    0 -1.386294        7     50   \n",
       "\n",
       "        lpsa train  \n",
       "9   1.047319     F  \n",
       "62  2.853592     F  \n",
       "37  2.157559     T  \n",
       "97  5.582932     F  \n",
       "51  2.656757     T  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_ind = np.random.randint(0, prostate_data.shape[0], 5)\n",
    "prostate_data.iloc[random_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas' `sample` method makes this even easier, and allows for custom sampling probabilities when non-uniform sampling is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.771557</td>\n",
       "      <td>3.896909</td>\n",
       "      <td>61</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.781709</td>\n",
       "      <td>3.451574</td>\n",
       "      <td>63</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>0</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>1.713798</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2.648300</td>\n",
       "      <td>3.582129</td>\n",
       "      <td>69</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.583998</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>3.457893</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.542324</td>\n",
       "      <td>4.178226</td>\n",
       "      <td>70</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>2.806386</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.182322</td>\n",
       "      <td>3.804438</td>\n",
       "      <td>65</td>\n",
       "      <td>1.704748</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.008214</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45  \\\n",
       "44  1.771557  3.896909   61 -1.386294    0  0.810930        7      6   \n",
       "24  1.781709  3.451574   63  0.438255    0  1.178655        7     60   \n",
       "79  2.648300  3.582129   69 -1.386294    1  2.583998        7     70   \n",
       "59  0.542324  4.178226   70  0.438255    0 -1.386294        7     20   \n",
       "32  0.182322  3.804438   65  1.704748    0 -1.386294        6      0   \n",
       "\n",
       "        lpsa train  \n",
       "44  2.374906     F  \n",
       "24  1.713798     T  \n",
       "79  3.457893     T  \n",
       "59  2.806386     T  \n",
       "32  2.008214     F  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prostate_data.sample(5, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Generate 20 samples with replacement from the prostate dataset, weighting samples inversely by age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Estimates\n",
    "\n",
    "From our bootstrapped samples, we can extract *estimates* of the expectation and its variance:\n",
    "\n",
    "$$\\bar{T}^* = \\hat{E}(T^*) = \\frac{\\sum_r T_r^*}{R}$$\n",
    "\n",
    "$$\\hat{\\text{Var}}(T^*) = \\frac{\\sum_r (T_r^* - \\bar{T}^*)^2}{R-1}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under appropriate regularity conditions, $\\frac{s^2}{\\hat{\\text{Var}}(T^*)} \\rightarrow 1$ as $n \\rightarrow \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Confidence Intervals\n",
    "\n",
    "There are a handful of ways for constructing confidence intervals from bootstrap samples, varying in ease of calculation and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Normal Interval\n",
    "\n",
    "Perhaps the simplest bootstrap interval is the normal interval:\n",
    "\n",
    "$$T_n ± z_{α/2} \\widehat{SE}_{boot}$$\n",
    "\n",
    "where $\\widehat{SE}_{boot}$ is an estimate of the standard error using the bootstrap sample. Of course, this interval is not accurate unless the distribution of $T_n$ is close to Gaussian.\n",
    "\n",
    "\n",
    "We can first define a **pivotal interval**. Let $\\theta = T(F)$ and $\\widehat{\\theta}_n = T(\\widehat{F}_n)$, and further define $P_n = \\widehat{\\theta}_n - \\theta$. \n",
    "\n",
    "Let $H(p)$ denote the CDF of the pivot:\n",
    "\n",
    "$$\n",
    "H(p) = Pr_F(P_n \\le p)\n",
    "$$\n",
    "\n",
    "Now define the interval $C_n = (a, b)$ where:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "a &= \\widehat{\\theta}_n - H^{-1}(1-\\alpha/2) \\\\\n",
    "b &= \\widehat{\\theta}_n - H^{-1}(\\alpha/2).\n",
    "\\end{aligned}$$\n",
    "\n",
    "It can be shown that $C_n$ is an exact $1 - \\alpha$ confidence interval for $\\theta$. But clearly, $a$ and $b$ depend on the unknown $H$. \n",
    "\n",
    "A pivot confidence interval uses a bootstrap estimate of H as an approximation:\n",
    "\n",
    "$$\\widehat{H}_P = \\frac{1}{R} \\sum_r I\\left[(\\widehat{\\theta}_{nr} - \\widehat{\\theta}_{n.}) < p\\right]$$\n",
    "\n",
    "From this, an approximate $1-\\alpha$ confidence interval is $C_n = (\\widehat{a}, \\widehat{b})$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\widehat{a} &= \\widehat{\\theta}_n - \\widehat{H}^{-1}(1-\\alpha/2) = 2\\widehat{\\theta}_n - \\theta^*_{1 - \\alpha/2} \\\\\n",
    "\\widehat{b} &= \\widehat{\\theta}_n - \\widehat{H}^{-1}(\\alpha/2) = 2\\widehat{\\theta}_n - \\theta^*_{\\alpha/2}.\n",
    "\\end{aligned}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the pivot interval for the standard deviation of the log-weights in the prostate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42619720436063674"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = prostate_data.lweight.copy()\n",
    "n = weights.shape[0]\n",
    "weights.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 97)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = 1000\n",
    "samples = np.array([weights.sample(n, replace=True) for r in range(R)])\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = weights.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = samples.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3589686 , 0.49657862])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*theta_hat - np.percentile(estimates, [97.5, 2.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach for calculating a pivotal interval is to define:\n",
    "\n",
    "$$Z_n = \\frac{T_n - \\theta}{\\widehat{SE}_{boot}}$$\n",
    "\n",
    "which can be approximated with: \n",
    "\n",
    "$$Z^*_{nr} = \\frac{T^*_{nr} - T_n}{\\widehat{SE}^*_{boot}}$$\n",
    "\n",
    "where $\\widehat{SE}^*_{boot}$ is the standard error of $T^*_{nr}$.\n",
    "\n",
    "Here, the quantiles of $Z^*_{n1}, \\ldots, Z^*_{nR}$ should approximate the true quantiles of the distribution of $Z_n$. We can then calculate the following interval:\n",
    "\n",
    "$$C_n = (T_n - z^*_{1-\\alpha/2}\\widehat{SE}_{boot}, T_n - z^*_{\\alpha/2}\\widehat{SE}_{boot})$$\n",
    "\n",
    "where $z^*_{a}$ is the $a$ sample quantile of $Z^*_{n1}, \\ldots, Z^*_{nR}$.\n",
    "\n",
    "This is a **studentized pivotal interval**.\n",
    "\n",
    "This interval is more computationally-intensive because $\\widehat{SE}^*_{boot}$ has to be calculated for each bootstrap sample, but it has better accuracy than the non-studentized interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a function to calculate studentized pivotal intervals for arbitrary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Percentile Intervals\n",
    "\n",
    "An even simpler interval involves using the empirical quantiles of the bootstrapped statistics. Consider a monotone transformation $U = m(T)$ such that $U \\sim N(m(\\theta), c^2)$. Importantly, we don't need to know what $m$ is, only that it exists. If we let $U^*_r = m(T^*_r)$, then $U^*_{(R\\alpha/2)} = m(T^*_{(R\\alpha/2)})$ because the monotone transformation preserves the quantiles.\n",
    "\n",
    "Since $U \\sim N(m(\\theta), c^2)$, the $\\alpha/2$ quantile of $U$ is $m(\\theta) - z_{\\alpha/2} c$. From this, it can be shown that:\n",
    "\n",
    "$$Pr(T^*_{R\\alpha/2} \\le \\theta \\le T^*_{R(1 - \\alpha/2)}) = Pr\\left( -z_{\\alpha/2} \\le \\frac{U - m(T)}{c} \\le z_{\\alpha/2} \\right) = 1 - \\alpha$$\n",
    "\n",
    "This employs the *ordered* bootstrap replicates:\n",
    "\n",
    "$$T_{(1)}^*, T_{(2)}^*, \\ldots, T_{(R)}^*$$\n",
    "\n",
    "Simply extract the $100(\\alpha/2)$ and $100(1-\\alpha/2)$ percentiles:\n",
    "\n",
    "$$T_{[(R+1)\\alpha/2]}^* \\lt \\theta \\lt T_{[(R+1)(1-\\alpha/2)]}^*$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract subset of varibles, and take bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = prostate_data[['lcavol', 'lweight', 'lbph', 'lcp', 'lpsa']]\n",
    "\n",
    "bootstrap_data = (data_subset.sample(data_subset.shape[0], replace=True) for _ in range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will user scikit-learn's `LinearRegression` model to fit a regression model to each bootstrap sample, and store the resulting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regmod = LinearRegression()\n",
    "\n",
    "# Empty array to store estimates\n",
    "coefs = np.empty((1000, 4))\n",
    "\n",
    "for i,X in enumerate(bootstrap_data):\n",
    "    y = X.pop('lpsa')\n",
    "    regmod.fit(X, y)\n",
    "    coefs[i] = regmod.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58408286, 0.58997744, 0.0548536 , 0.09313663])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort coefficients, and extract percentiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.sort(axis=0)\n",
    "boot_se = coefs[[25, 975], :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS/ElEQVR4nO3dfZBddX3H8ffXRIEAmpkADrCB0JqgDqWZCKWoQSxQSwZGWx5jpGLVCEzjrIVpKw9KxcB0inXrGCRkLLGQRhRaHSFUC20wSrBUWJ4sRB7yBFQexqA2kI7h2z/uWXr37iZ7NznJ3fvb92vmzDnn9/vds997uPncwzlnz0ZmIkkqz+s6XYAkadcw4CWpUAa8JBXKgJekQhnwklSoiZ0uACAi9gCOBp4Ftna4HEnqFhOAA4F7M3NLa+eYCHga4b6q00VIUpeaDfygtXGsBPyzAKtWraKnp6fTtUhSV9i4cSOzZ8+GKkNbjZWA3wrQ09PDtGnTOlyKJHWdYU9te5FVkgplwEtSoQx4SSqUAS9JhTLgJalQBrwkFcqAV+f09jYmSbvEWLkPXuNRf3+nK5CKNuIRfERcHRFPRURGxBHbGDMhIhZFxBMR8XhEfKz+UiVJo9HOKZpvAccB67YzZh7wFmA6cCxweURM29niJEk7bsSAz8wfZOaGEYadBSzJzFcz83kaXwpn1FCfJGkH1XUO/hAGH+GvB6YONzAiJgOTW5p9wpgk1awTF1l7gc924OdK0rhS122S64FDm9YPAbZ1WqcPOKxlml1THZKkSl1H8N8EPh4R/wRMAT5A48LsEJm5CdjU3BYRNZUhSRrQzm2SX4qIjTTOk98REY9U7Ssi4qhq2A3Ak8BPgXuAz2Xmk7uoZklSG0Y8gs/MTwKfHKZ9TtPyVuD8ekuTJO0MH1UgSYUy4CWpUAa8JBXKgJekQhnwklQoA16SCmXAS1KhDHhJKpQBL0mFMuAlqVAGvCQVyoCXpEIZ8JJUKANekgplwEtSoQx4SSqUAS9JhTLgJalQBrwkFcqAl6RCGfCSVCgDXpIKZcBLUqEMeEkqlAEvSYUy4CWpUAa8JBXKgJekQrUV8BExIyJWR8Saaj59mDEHRMRtEfFgRDwaEddExMT6S5YktaPdI/hrgUWZOQNYBCweZszFwH9l5pHAbwHvAP6oliolSaM2YsBHxAHALGB51bQcmBUR+7cMTWDfiHgdsAfwBuDpGmuVJI1CO6dQpgJPZ+ZWgMzcGhHPVO3PN427ArgFeBbYG/hyZv6wdWMRMRmY3NLcM+rKJUnbVedF1jOAB4EDgYOB4yLi9GHG9QJPtUyraqxDkkR7Ab8BODgiJgBU84Oq9mYLgGWZ+WpmvgR8G3jvMNvrAw5rmWbvUPWSpG0aMeAz8zmgH5hbNc0F7s/M51uGPgX8AUBEvAE4EXh4mO1tysy1zROwcYffgSRpWO2eojkPWBARa2gcqZ8HEBErIuKoakwvMDsiHqLxhbAGWFJrtZKktrV1n3pmPgocM0z7nKblJ4CT6itNkrQz/E1WSSqUAS9JhTLgJalQBrwkFcqAl6RCGfCSVCgDfjR6exuTJHUBn9c+Gv39na5AktrmEbwkFcqAl6RCGfCSVCgDXpIKZcBLUqEMeEkqlAEvSYUy4CWpUAa8JBXKgJekQhnwklQoA16SCmXAS1KhDHhJKpQBL0mFMuAlqVAGvCQVyoCXpEIZ8JJUKANekgrVVsBHxIyIWB0Ra6r59G2MOzMiHoqIh6v5m+stV5LUrnaP4K8FFmXmDGARsLh1QEQcBVwOnJSZRwDvBl6qqU5J0iiNGPARcQAwC1heNS0HZkXE/i1DPwVcnZn/DZCZL2XmK8Nsb3JETGuegJ6deRPqQsuWwT33wF13wbRpjXVJtWrnCH4q8HRmbgWo5s9U7c3eDvxGRHw/Iu6LiEsjIobZXi/wVMu0agfr330MpPosWwbz58OWLY31desa6+5TqVZ1XmSdCBwJnAS8BzgZOGeYcX3AYS3T7BrrqJ+BVK9LLoHNmwe3bd7caJdUm3YCfgNwcERMAKjmB1XtzdYBN2fmlsz8JfBt4HdaN5aZmzJzbfMEbNyZN7HLGUj1Wr9+dO2SdsiIAZ+ZzwH9wNyqaS5wf2Y+3zL0H4Hfj4bXAycAD9RYa+cYSPU65JDRtUvaIe2eojkPWBARa4AF1ToRsaK6ewbg68BzwE9ofCE8Any11mo7xUCq18KFMGnS4LZJkxrtkmozsZ1BmfkocMww7XOall8F/qyayrJwYeOce/NpGgNpx82b15h/9KON6xqHHtrYlwPtkmrRVsCPewZS/ebNgyVLGssrV3a0FKlUBny7DCRJXcZn0UhSoQx4SSqUAS9JhTLgJalQBrwkFcqAl6RCGfCSVCgDXpIKZcBLUqEMeEkqlAEvSYUy4CWpUAa8JBXKgJekQhnwklQoA16SCmXAS1KhDHhJKpQBL0mFMuAlqVAGvCQVyoCXpEIZ8JJUqImdLqCrzJzZ6QokqW0G/Gj09XW6Aklqm6doJKlQbQV8RMyIiNURsaaaT9/O2MMjYnNEXF1fmZKk0Wr3CP5aYFFmzgAWAYuHGxQRE6q+b9VSnSRph414Dj4iDgBmASdVTcuBL0fE/pn5fMvwvwRuBfappuG2NxmY3NLc037JkqR2tHMEPxV4OjO3AlTzZ6r210TEkcD7gC+OsL1e4KmWadWoqpYkjaiWu2gi4vXAEuAjmbk1IrY3vA9Y2tLWgyEvSbVqJ+A3AAdHxIQqvCcAB1XtAw4EfhNYUYX7ZCAi4o2ZOb95Y5m5CdjU3DbCF4IkaQeMGPCZ+VxE9ANzgRur+f3N598zcz2w38B6RFwO7JOZF9VdsCSpPe3eRXMesCAi1gALqnUiYkVEHLWripMk7bi2zsFn5qPAMcO0z9nG+Mt3rixJ0s7yN1klqVAGvCQVyoCXpEIZ8JJUKANekgplwEtSoQx4SSqUAS9JhTLgJalQBrwkFcqAl6RCGfCSVCgDXpIKZcBLUqEMeEkqlAEvSYUy4CWpUAa8JBXKgJekQhnwklQoA16SCmXAS1Kr3t7G1OUmdroASRpz+vs7XUEtPIKXpEIZ8JJUKANekgplwEtSodoK+IiYERGrI2JNNZ8+zJjLIuKRiHggIn4cEe+rv1xJUrvaPYK/FliUmTOARcDiYcb8B3B0Zv428CfATRGxVz1lSpJGa8SAj4gDgFnA8qppOTArIvZvHpeZ383MzdXqg0AAU2qsVZI0Cu3cBz8VeDoztwJk5taIeKZqf34br/lj4InM3NjaERGTgcktzT3tFixJak/tv+gUEe8BrgBO2saQXuCzdf9cSdJg7QT8BuDgiJhQHb1PAA6q2geJiGOBG4H3Z+Zj29heH7C0pa0HWNVu0ZKkkY0Y8Jn5XET0A3NphPdc4P7MHHR6JiKOBm4CTs/M+7azvU3AppbXjrZulWDmzE5XIBWt3VM05wFfi4jPAD+ncY6diFgBfCYz/xO4BtgLWNwU2Odk5kP1lqxi9PV1ugKpaG0FfGY+ChwzTPucpuWja6xL0mgMPPnQL0018WmSUgkKefqh6uWjCiSpUAa8JBXKgJekQhnwklQoA16SCmXAS1KhDHhJKpQBL0mFMuAlqVAGvCQVyoCXpEIZ8JLUbNkyuOceuOsumDatsd6lDHhJGrBsGcyfD1u2NNbXrWusd2nIG/CSNOCSS2Dz5sFtmzc32ruQAS9JA9avH137GGfAS9KAQw4ZXfsYZ8BL0oCFC2HSpMFtkyY12ruQAS9JA+bNg+uugz32aKwfemhjfd68zta1g/yTfVK3G7itb8uWxm19Cxd2bSCNCfPmwZIljeWVKztays7yCF7qZoXd1qd6GfBSNyvstj7Vy4CXullht/WpXga81M0Ku61P9TLgpW5W2G19qpcBL3Wzwm7rU728TVLqdgXd1qd6eQQvSYVqK+AjYkZErI6INdV8+jBjJkTEooh4IiIej4iP1V+uJKld7R7BXwssyswZwCJg8TBj5gFvAaYDxwKXR8S0OoqUJI3eiAEfEQcAs4DlVdNyYFZE7N8y9CxgSWa+mpnPA98CzqixVknSKLRzkXUq8HRmbgXIzK0R8UzV/nzTuEOAdU3r66sxg0TEZGByS3MPwNlnn82ee+75WuOZZ57JBRdcwObNm5kzZ86Qws4991zOPfdcXnjhBU4//fQh/eeffz5nnXUWGzZs4JxzzhnSf+GFF3Lqqafy2GOP8YlPfGJI/6WXXsqJJ55If38/vb29Q/qvvPJK3vnOd3L33Xdz8cUXD+nv6+tj5syZ3HHHHXz+858f0r948WIOP/xwvvOd7/CFL3xhSP8NN9zA1KlTuemmm/jKV74ypP/mm29mv/32Y+nSpSxdunRI/4oVK5g0aRLXXHMN3/jGN4b0r6wuyF199dXceuutg/r22msvbr/9dgCuuOIK7rzzzkH9U6ZM4ZZbbgHg05/+NKtXrx7U39PTw4033ghAb28v/f39g/pnzJjBddddB8D8+fNZs2bNoP6ZM2fS19cHwIc+9CE2btw4qP/YY4/lqquuAuC0007jxRdfHNR/wgkncNlllwFw8skn8/LLLw/qP+WUU7jooosAOP7442nVbZ+9vmr/9lbvxc/eTn72quWx/tk7++yzh/Q368RdNL3AZzvwcyVpXInM3P6AximaNcCU6uh9AvAiML06FTMw7jbg+sy8uVr/MrAuM/+mZXuTGf4IftVTTz3FtGnTduoNSePSwJGgt0nWo0v259q1aznssMMADsvMta39I56Dz8zngH5gbtU0F7i/Odwr3wQ+HhGvq87PfwC4ZZjtbcrMtc0TsLF1nCRp57R7F815wIKIWAMsqNaJiBURcVQ15gbgSeCnwD3A5zLzyZrrlSS1qa1z8Jn5KHDMMO1zmpa3AufXV5okaWf4m6ySVCgDXpIK5cPGJKnVzJmdrqAWBrxUgkICacyofsmu2xnwUgkKCSTVy3PwklQoA16SCmXAS1KhDHhJKpQBL0mFMuAlqVAGvCQVaqzcBz8BGPKXUyRJ29aUmROG6x/xD37sDhHxbmBVp+uQpC41OzN/0No4VgJ+D+Bo4Flga4fL2Z4eGl9Es/GPlNTB/Vkf92W9umV/TgAOBO7NzC2tnWPiFE1V2JBvn7EmIgYWNw7357E0Ou7P+rgv69Vl+/OJbXV4kVWSCmXAS1KhDHhJKpQBPzqbgL+q5tp5m3B/1mUT7ss6baKA/Tkm7qKRJNXPI3hJKpQBL0mFGpcBHxEZEfvs5p+5MiJO2Z0/c1eoc99FRH9E7NXGuLURccQ2+noj4oA66hmLmvf39vbDCNvYodeNB53Igt1pXAa8xobMnJmZL+/kZnqBYgNe2hnjPuAj4m0R8b2IeDAiHoqID1ftF0bEvRFxf0SsjoiZVftlEfHFptdPiYgXI2LviNgnIq6PiIer6S869LZ2uYh4X0TcVi0fUB0JnVGt/3lEXFktHx4Rt1f78oGI+EjTNpqPTmdX+//BiPi7iFjXctR5ZvXfYW1E/Gn1mkuAg4Cbq/8bePtuevudNC8ivh8Rjw/sB3jtKP2q4foqQ/afBttOFqyMiL5q/vjAZ7srZOa4m4AE9qHxqIY1wBlNfVOq+f5NbScC91TLh9B4Zs7Ean0B8PfV8l8DXwMCeCPwCHBy1bcSOKXT773GfTcJeBF4PTAXuBu4thrzXeCEav/+GHhr1b4v8FjT+sC29qDxvI/ZVfsfVn1HVOtrgaur5WnAr4B9mvqO6PR+2dX7u+m9DnzW3gw8AxzZZt+w+2+8T21mwUrge9WYfYCHuuXf8ng/gj+cRlB/c6AhM1+sFt9RHQ09DPwtMLPqXw/8BJhTjTsXuL5aPhFYkg2/AJZXbcXJzM00vsCOofEePwe8KyLeABwF/BCYAbwN+HpE9NN4eNMeVVuzw4GXM3NVte1/Zuj9x1+v+tYCP6fxMKjx6KsAmfkz4Dbg+Db73H/bt70sAPhaZv46M39FY1/+3u4ucEeMiYeNdVAM29gIqZuB4zLzvog4CHi6achS4MMR8STwpoFgqrbX+osFJf+iwZ00jtR/Fzgf+BnwQeCBzHwlGk9seiEzZ46wneH2W6tXmpa34mcXtr/fWvvcf9s3bBZsZ2xX/Lse70fwjwK/Hjh3DI1z6sCeNP4BbKiaL2h53S3AccBFNMJ+wL8CH4uGfYGzgTt2Teljwp3AR4ANmfm/1frl1Rwap2M2R8Q5Ay+IiLdGxBtbtvMosHdEvKsa835gcps1/AJ4046+gS50LkBE7A+cTOP0QTt92r5tZcGAcyJiYkTsDZwB/PvuLnBHjOuAz8xfA+8HzqsuqjwAzKlOr3wGuDcivg/8T8vrNgPfBs4B/qGp6woa3+4PAauBGzLzX3b9O+mYHwH78f+BfidwKPBv8Nr+PRU4u7pw9QhwDfCG5o1k43HRHwSujYgf0fg/gp8BL7VRw5eA68fRRdb1EbGKxufrqsx8qM0+bce2sqBpyH00Dtb6gdsy89bdX+Xo+agCjQkRsW9m/rJafi+Ni9XTMvPVzlbWHSJiLY0Lfw93upbSRMRKGhepuyLUm3keTmPFaRHxKRr/V/kKMNdwl3aOR/CSVKhxfQ5ekkpmwEtSoQx4SSqUAS9JhTLgJalQBrwkFer/AOExIvSftGw3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot means\n",
    "coef_means = coefs.mean(0)\n",
    "plt.plot(coef_means, 'ro')\n",
    "\n",
    "# Plot bootstrap intervals\n",
    "for i in range(len(coef_means)):\n",
    "    plt.errorbar(x=[i,i], y=boot_se[i], color='red')\n",
    "    \n",
    "plt.xlim(-0.5, 3.5)\n",
    "plt.xticks(range(len(coef_means)), ['lcavol', 'lweight', 'lbph', 'lcp'])\n",
    "plt.axhline(0, color='k', linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that the pivot confidence interval is generally more accurate than the percentile interval.\n",
    "\n",
    "Also, its important to remember that the bootstrap is an **asymptotic method**. So, the coverage of the confidence interval is expected to be $1 - \\alpha + r_n$ where $r_n \\propto 1/\\sqrt{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Bootstrap\n",
    "\n",
    "The bootstrap approaches we have outlined above are all non-parametric, though parametric inference is possible. If we have $X_1, \\ldots, X_n \\sim p(x|\\theta)$, where $\\widehat{\\theta}$ is the MLE, then let $\\phi = g(\\theta)$ and $\\widehat{\\phi} = g(\\widehat{\\theta})$.\n",
    "\n",
    "An approach for estimating the standard error of $\\widehat{\\phi}$ is to compute the standard deviation of the bootstrapped $\\hat{\\phi^*}_1, \\ldots, \\hat{\\phi^*}_R$. To do this, we can draw bootstrap samples from the **parametric** distribution $p(x|\\widehat{\\theta})$:\n",
    "\n",
    "$$\\widehat{X}_1^*, \\ldots, \\widehat{X}_n^* \\sim p(x|\\widehat{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "Wasserman, L. (2006). All of Nonparametric Statistics. Springer Science & Business Media."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
