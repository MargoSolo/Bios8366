{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fonnesbeck/Bios8366/blob/master/notebooks/Section3_1-Expectation-Maximization.ipynb)\n",
    "\n",
    "# Expectation Maximization Algorithm\n",
    "\n",
    "Максимизация ожиданий (EM, Dempster et al. 1977) использует итеративную оптимизацию вместе с моделью скрытых переменных для получения оценок максимального правдоподобия для моделей, параметры которых трудно оценить напрямую. Алгоритм был мотивирован вменением отсутствующих данных. Однако недостающие значения могут быть преднамеренно введены в проблему в качестве концептуальной уловки, упрощающей получение решения.\n",
    "\n",
    "Может быть не интуитивно понятно, как введение скрытых (отсутствующих) элементов в проблему облегчит ее решение, но по сути это работает, разбивая оптимизацию на два этапа:\n",
    "\n",
    "1. генерация **ожиданий** по отсутствующим переменным(ям) на основе текущих оценок параметров\n",
    "2. **максимизация** логарифмического правдоподобия на шаге ожидания, тем самым генерируя обновленные оценки параметров.\n",
    "\n",
    "EM особенно подходит для оценки параметров *смешанных моделей*, когда мы не знаем, из какого компонента получено каждое наблюдение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, предположим, что мы имеем наблюдаемые величины $x = x_1,\\ldots,x_n$ и ненаблюдаемые (скрытые) величины $z = z_1,\\ldots,z_m$, полученные из некоторой совместной модели:\n",
    "\n",
    "$$y = (x,z) \\sim P(x,z|\\theta)$$\n",
    "\n",
    "Нас интересует получение MLE для маргинального распределения $X$:\n",
    "\n",
    "$$x \\sim P(x|\\theta)$$\n",
    "\n",
    "Однако трудно маргинализировать свыше $Z$ и максимизировать. EM обходит это, многократно улучшая начальную оценку $\\theta^{(0)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Mixture of normals\n",
    "\n",
    "Рассмотрим набор наблюдений, каждое из которых было взято из одной из двух совокупностей:\n",
    "\n",
    "$$x^{(a)} \\sim N(\\mu_a, \\sigma^2_a)$$\n",
    "$$x^{(b)} \\sim N(\\mu_b, \\sigma^2_b)$$\n",
    "\n",
    "за исключением того, что мы наблюдаем только значения для $x = [x^{(a)}, x^{(b)}]$, а не метки, которые определяют, из какой совокупности они получены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(77)\n",
    "\n",
    "# True parameter values\n",
    "mu_true = np.array([2, 5])\n",
    "sigma_true = np.array([0.5, 1])\n",
    "psi_true = .6\n",
    "n = 100\n",
    "\n",
    "# Simulate from each distribution according to mixing proportion psi\n",
    "z = np.random.binomial(1, psi_true, n)\n",
    "x = np.random.normal(mu_true[z], sigma_true[z])\n",
    "\n",
    "_ = plt.hist(x, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда наблюдаемые данные представляют собой конечную смесь нормальных распределений:\n",
    "\n",
    "$$X = (1 - \\psi)X^{(a)} + \\psi X^{(b)}$$\n",
    "\n",
    "Это генеративное представление данных, при котором ненаблюдаемые метки $z_i$ генерируются в соответствии с вероятностью $\\psi$. Мы можем попытаться максимизировать логарифмическую вероятность совместного распределения выше с помощью максимальной вероятности:\n",
    "\n",
    "$$l(\\theta) = \\sum_i \\log\\left[(1 - \\psi)\\phi^{(a)}(x_i) + \\psi \\phi^{(b)}(x_i)\\right] $$\n",
    "\n",
    "$$\\text{where } \\theta = \\{\\psi, \\mu^{(a)}, \\sigma^{(a)}, \\mu^{(b)}, \\sigma^{(b)}\\}$$\n",
    "\n",
    "Однако эту функцию очень трудно максимизировать, и она оказывается бимодальной. Более простой подход состоит в том, чтобы рассматривать метки данных как ненаблюдаемые данные и включать их в модель. Обычно это называется подходом *дополнения к данным*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совместное распределение $x$ и $z$ можно разложить на:\n",
    "\n",
    "$$P(x_i,z_i) = P(x_i \\,|\\, z_i)P(z_i)$$\n",
    "\n",
    "Разумно моделировать $z$ как:\n",
    "\n",
    "$$\\{z_i\\} \\sim \\text{Bernoulli}(\\psi)$$\n",
    "\n",
    "где $\\psi$ — вероятность принадлежности к группе «b» (отсюда $1-\\psi$ — вероятность принадлежности к группе «a»). Обратите внимание, что это обобщается на $k$ компонентов в смеси, где $z_i \\sim \\text{Multinomial}(\\psi)$ с $\\psi$ размерности $k-1$.\n",
    "\n",
    "Clearly, the distribution of $x$ conditional on $z$ is:\n",
    "\n",
    "$$(x_i | z_i = j) \\sim N(\\mu_j, \\sigma_j)$$\n",
    "\n",
    "Если бы мы знали $\\{z_i\\}$, мы могли бы просто использовать MLE для получения оценок параметров модели. Однако мы не знаем ярлыков, что делает это формой **обучения без учителя**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "Продолжая использовать модель смеси нормалей в качестве нашего примера, мы можем применить алгоритм EM для оценки $\\theta = \\{\\mu, \\sigma, \\psi\\}$.\n",
    "\n",
    "> **Initialize** $\\theta_0 = \\{\\mu_0, \\sigma_0, \\psi_0\\}$\n",
    "> \n",
    "> **Repeat until convergence:**\n",
    "> \n",
    "> - **E-step**: guess the values of $\\{z_i\\}$\n",
    "> \n",
    ">     Compute probabilities of group membership: $w_{ij} = P(z_i = j | x_i, \\theta)$ for each group $j=1,\\ldots,k$. This is done via Bayes' formula:\n",
    ">     \n",
    ">     $$P(z_i = j | x_i) = \\frac{P(x_i | z_i=j) P(z_i=j)}{\\sum_{l=1}^k P(x_i | z_i=l) P(z_i=l)}$$\n",
    ">     \n",
    ">     $\\theta$ has been dropped for notational convenience.\n",
    ">     \n",
    "> - **M-step**: update estimates of parameters $\\theta$\n",
    "> \n",
    ">     $$\\begin{aligned}\\psi_j &= \\frac{1}{n} \\sum_i w_{ij} \\\\\n",
    "       \\mu_j &= \\frac{\\sum_i w_{ij} x_i}{\\sum_i w_{ij}} \\\\\n",
    "       \\sigma_j^2 &= \\frac{\\sum_i w_{ij}(x_i - \\mu_j)^2}{\\sum_i w_{ij}}\n",
    "     \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General formulation\n",
    "\n",
    "Recall [**Jensen's inequality**](http://mathworld.wolfram.com/JensensInequality.html):\n",
    "\n",
    "> Let $f$ be a convex function (*i.e.* $f^{\\prime\\prime} \\ge 0$) of a random variable X. Then:\n",
    "> $f(E[X]) \\le E[f(X)]$\n",
    "\n",
    "And when $f$ is *strictly* convex, then:\n",
    "\n",
    "$$E[f(X)] = f(E[X]) \\iff X = E[X]$$\n",
    "\n",
    "with probability 1.\n",
    "\n",
    "Consider again the joint density $P(x,z|\\theta)$, where only $x$ is observed. We want to be able to maximize:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "l(x \\,|\\, \\theta) &= \\sum_i \\log P(x_i \\,|\\, \\theta) \\\\\n",
    "&= \\sum_i \\log \\sum_{z_i} P(x_i, z_i \\,|\\, \\theta)\n",
    "\\end{aligned}$$\n",
    "\n",
    "however, evaluating this is difficult when the $\\{z_i\\}$ are unobserved.\n",
    "\n",
    "The EM algorithm iteratively calculates *lower bounds on the likelihood* for the current values of the parameters, then *maximizes the lower bound* to update the parameters.\n",
    "\n",
    "Since $z_i$ is a random variable, perhaps we can construct its density $Q_i$ and use it to marginalize the joint likelihood:\n",
    "\n",
    "$$\\sum_i \\log \\sum_{z_i} P(x_i, z_i \\,|\\, \\theta) = \\sum_i \\log \\sum_{z_i} Q_i(z_i) \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)}$$\n",
    "\n",
    "This turns the inner summation into an expectation.\n",
    "\n",
    "$$\\sum_i \\log \\sum_{z_i} Q_i(z_i) \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} = \\sum_i \\log E_{Q_i} \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right]$$\n",
    "\n",
    "Now, if we apply Jensen's inequality (note that the logarithm is a *concave* function, so the inequality is reversed):\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\sum_i \\log E_{Q_i} \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right] &\\ge \\sum_i  E_{Q_i} \\log \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right] \\\\\n",
    "&= \\sum_i \\sum_{z_i}  Q_i(z_i) \\log \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right]\n",
    "\\end{aligned}$$\n",
    "\n",
    "We need to ensure that the equality condition holds true, which we can do by choosing $Q_i$ appropriately. Specifically, we want a $Q_i$ such that:\n",
    "\n",
    "$$\\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} = C$$\n",
    "\n",
    "which implies:\n",
    "\n",
    "$$Q_i(z_i) \\propto P(x_i, z_i \\,|\\, \\theta)$$\n",
    "\n",
    "Since $Q_i$ is a density,\n",
    "\n",
    "$$\\begin{aligned}\n",
    "Q_i(z_i) &= \\frac{P(x_i, z_i \\,|\\, \\theta)}{\\sum_{z_i} P(x_i, z_i \\,|\\, \\theta)} \\\\\n",
    "&= \\frac{P(x_i, z_i \\,|\\, \\theta)}{P(x_i \\,|\\, \\theta)} \\\\\n",
    "&= P(z_i \\,|\\, x_i, \\theta)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to our normal mixture example:\n",
    "\n",
    "For the **E-step** we need to identify $Q_i(z_i)$\n",
    "\n",
    "$$Q_i(z_i) = P(z_i \\,|\\, x_i, \\mu, \\sigma, \\psi)$$\n",
    "\n",
    "Via Bayes' formula:\n",
    "\n",
    "$$P(z_i=j \\,|\\, x_i) = \\frac{P(x_i \\,|\\, z_i=j)P(z_i=j)}{\\sum_l P(x_i \\,|\\, z_i=l)P(z_i=l)}$$\n",
    "\n",
    "where $P(x_i \\,|\\, z_i=j)$ is just the $j$ th Normal distribution of the mixture, and $P(z_i=j)$ is a multinomial probability.\n",
    "\n",
    "This gives us:\n",
    "\n",
    "$$P(z_i=1 \\,|\\, x_i) = \\frac{\\psi N(\\mu_b, \\sigma_b^2)}{\\psi N(\\mu_a, \\sigma_a^2) + (1-\\psi) N(\\mu_b, \\sigma_b^2)}$$\n",
    "\n",
    "(recall that we are encoding `a=0` and `b=1`)\n",
    "\n",
    "This can be implemented easily in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm\n",
    "\n",
    "def e_step(x, mu, sigma, psi):\n",
    "    a = psi * norm.pdf(x, mu[0], sigma[0])\n",
    "    b = (1. - psi) * norm.pdf(x, mu[1], sigma[1])\n",
    "    return b / (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001415844457163535"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_step(0.4, mu_true, sigma_true, psi_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x170a4a73b20>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_range = np.linspace(-5,5)\n",
    "plt.plot(x_range, e_step(x_range, mu_true, sigma_true, psi_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **M-step** we need to maximize\n",
    "\n",
    "$$\\begin{aligned}\\text{argmax}_{\\mu,\\Sigma, \\psi}  \\sum_i \\sum_{z_i}  Q_i(z_i) \\log \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right] \\\\\n",
    "= \\sum_i \\sum_{z_i} w_{ij} \\log \\left[\\frac{1}{\\sqrt{2 \\pi} \\, |\\Sigma_j|^{1/2} \\, w_{ij}} e^{-\\frac{1}{2} (x_i - \\mu_j) \\Sigma^{-1} (x_i - \\mu_j))} \\psi_j\\right]\n",
    "\\end{aligned}$$\n",
    "\n",
    "which we can show is\n",
    "\n",
    "$$\\begin{aligned}\\psi_j &= \\frac{1}{n} \\sum_i w_{ij} \\\\\n",
    "\\mu_j &= \\frac{\\sum_i w_{ij} x_i}{\\sum_i w_{ij}} \\\\\n",
    "\\sigma_j^2 &= \\frac{\\sum_i w_{ij}(x_i - \\mu_j)^2}{\\sum_i w_{ij}}\n",
    "\\end{aligned}$$\n",
    "\n",
    "This can be coded into Python as `m_step`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(x, w):\n",
    "    psi = np.mean(w) \n",
    "    \n",
    "    mu = [np.sum((1-w) * x)/np.sum(1-w), np.sum(w * x)/np.sum(w)]\n",
    "    \n",
    "    sigma = [np.sqrt(np.sum((1-w) * (x - mu[0])**2)/np.sum(1-w)), \n",
    "             np.sqrt(np.sum(w * (x - mu[1])**2)/np.sum(w))]\n",
    "    \n",
    "    return mu, sigma, psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: N(5.1992, 0.8529)\n",
      "B: N(2.4331, 0.7952)\n",
      "psi: 0.4435\n"
     ]
    }
   ],
   "source": [
    "# Initialize values\n",
    "mu = np.random.normal(size=2)\n",
    "sigma = np.random.uniform(0, 10, 2)\n",
    "psi = np.random.random()\n",
    "\n",
    "# Stopping criterion\n",
    "crit = 1e-4\n",
    "\n",
    "# Convergence flag\n",
    "converged = False\n",
    "\n",
    "# Loop until converged\n",
    "while not converged:\n",
    "    \n",
    "    # E-step\n",
    "    w = e_step(x, mu, sigma, psi)\n",
    "    # M-step\n",
    "    mu_new, sigma_new, psi_new = m_step(x, w)\n",
    "    \n",
    "    # Check convergence\n",
    "    converged = ((np.abs(psi_new - psi) < crit) \n",
    "                 & np.all(np.abs((np.array(mu_new) - np.array(mu)) < crit))\n",
    "                 & np.all(np.abs((np.array(sigma_new) - np.array(sigma)) < crit)))\n",
    "    mu, sigma, psi = mu_new, sigma_new, psi_new\n",
    "                \n",
    "print('A: N({0:.4f}, {1:.4f})\\nB: N({2:.4f}, {3:.4f})\\npsi: {4:.4f}'.format(\n",
    "                        mu_new[0], sigma_new[0], mu_new[1], sigma_new[1], psi_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Zero-inflated data\n",
    "\n",
    "Code the EM algorithm to estimate the paramters of a zero-inflated Poisson (ZIP) model.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f(x \\mid \\theta, \\psi) &\\sim& \\left\\{ \\begin{array}{l}\n",
    "            \\text{Poisson}(\\theta) \\text{ w.p. } \\psi \\\\\n",
    "            0 \\text{ w.p. } 1-\\psi\n",
    "            \\end{array} \\right. \\\\\n",
    "&=& \\left\\{ \\begin{array}{l}\n",
    "            \\psi \\frac{e^{-\\theta}\\theta^x}{x!}, \\text{if } x=1,2,3,\\ldots \\\\\n",
    "            (1-\\psi) + \\psi e^{-\\theta}, \\text{if } x = 0\n",
    "            \\end{array} \\right.\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# True parameter values\n",
    "mu_true = 1.5\n",
    "psi_true = .4\n",
    "n = 100\n",
    "\n",
    "# Simulate some data\n",
    "data = np.array([np.random.poisson(mu_true)*(np.random.random()<psi_true) for i in range(n)])\n",
    "plt.hist(data, bins=9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(x, mu, psi):\n",
    "    \n",
    "    a = (1-psi) * (x==0)\n",
    "    b = psi * poisson.pmf(x, mu)\n",
    "    \n",
    "    return b / (a+b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(x, w):\n",
    "    \n",
    "    psi = np.mean(w)\n",
    "    \n",
    "    mu = np.sum(w*x)/np.sum(w)\n",
    "    \n",
    "    return mu, psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_em(mu0=1, psi0=0.5, x=data):\n",
    "    \n",
    "    # Initialize values\n",
    "    mu = mu0\n",
    "    psi = psi0\n",
    "\n",
    "    # Stopping criterion\n",
    "    crit = 1e-5\n",
    "\n",
    "    # Convergence flag\n",
    "    converged = False\n",
    "\n",
    "    # Loop until converged\n",
    "    while not converged:\n",
    "\n",
    "        # E-step\n",
    "        w = e_step(x, mu, psi)\n",
    "        # M-step\n",
    "        mu_new, psi_new = m_step(x, w)\n",
    "\n",
    "        # Check convergence\n",
    "        converged = ((np.abs(psi_new - psi) < crit) \n",
    "                     & np.all(np.abs((np.array(mu_new) - np.array(mu)) < crit)))\n",
    "        mu, psi = mu_new, psi_new\n",
    "\n",
    "    return mu, psi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3984619324892422, 0.4647963486878826)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_em()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Peppered moth genotype frequencies\n",
    "\n",
    "Peppered moths (*Biston betularia*) is an example of microevoloution occuring at human time scales. The coloring of the moth is determined by a single gene that is comprised of three alleles:\n",
    "\n",
    "* T\n",
    "* I (dominant to T)\n",
    "* C (dominant to I, T)\n",
    "\n",
    "thus, the genotype TT corresponds to the *typica* phenotype, which results in a light-colored wing pattern; CC, CI and CT results in the dark *carbonaria* phenytype; while IT and II encode an intermediate *insularia* phenotype.\n",
    "\n",
    "Prior to the industrial revolution, the lighter typical and insularia were common, but were eventually replaced by the darker typica phenotype. It is thought that differential predation resulted from the lighter phenotypes being conspicuous against tree bark darkened by pollution from the industrial use of coal; darker carbonaria strains were camoflauged against the darker trees, which offered protection from predation. When air quality standards were improved, the relative abundance of the lighter phenotypes increased to pre-industrial levels.\n",
    "\n",
    "![Gypsy moths](images/moth.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absent genetic methods for ascertaining the genotypes underlying each individual observed phenotype, we require statistical methods for estimating these frequencies. If we represent the three **allele freuqencies** by the variables $p_C$, $p_I$ and $p_T$, then the genotypes and corresponding frequencies are:\n",
    "\n",
    "* CC = $p_C^2$\n",
    "* CI = $2p_C p_I$\n",
    "* CT = $2p_C p_T$\n",
    "* II = $p_I^2$\n",
    "* IT = $2p_I p_T$\n",
    "* TT = $p_T^2$\n",
    "\n",
    "The genotype frequencies are *latent variables*. If we were able to count alleles, rather than phenotypes, estimating these frquencies would be straightforward.\n",
    "\n",
    "We are able to observe counts of phenotypes, $x_C$, $x_I$ and $x_T$, but not counts of genotypes, $X_{CC}, X_{CI}, X_{CT}, X_{II}, X_{IT}, X_{TT}$, except in the case of $X_{TT} = x_T$, since there is only one genotype that can produce this phenotype.\n",
    "\n",
    "If we had complete data, the latent allele frequencies could be estimated using a **multinomial model**:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f(x \\mid n, \\pi) &=& \\frac{n!}{\\prod_{i=1}^k x_i!} \\prod_{i=1}^k \\pi_i^{x_i} \\\\\n",
    "&=& \\frac{n!}{x_{CC}! x_{CI}! x_{CT}! x_{II}! x_{IT}! x_{TT}!} (p_C^2)^{x_{CC}} (2p_C p_I)^{x_{CI}} (2p_C p_T)^{x_{CT}} (p_I^2)^{x_{II}} (2p_I p_T)^{x_{IT}} (p_T^2)^{x_{TT}} \n",
    "\\end{aligned}$$\n",
    "\n",
    "We can use the EM algorithm to estimate the latent variables conditional on the data that we do observe. We first need to construct $Q(z) = P(z|x)$ so that this expectation can be calculated. For each unobserved genotype count, we need to estimate the proportion of the observed phenotype count that is contributed by that genotype. For example, in the case of the homozygous *carbonaria*:\n",
    "\n",
    "$$E[X_{CC}| x_{C}, x_{T}, x_{I}, \\mathbf{p}^{(t)}] = x_{(CC)}^{(t)} = \\frac{x_C (p_C^{(t)})^2}{(p_C^{(t)})^2 + 2p_C^{(t)} p_I^{(t)} + 2p_C^{(t)} p_T^{(t)}}$$\n",
    "\n",
    "Similarly, for genotype CI:\n",
    "\n",
    "$$E[X_{CI}| x_{C}, x_{T}, x_{I}, \\mathbf{p}^{(t)}] = x_{(CI)}^{(t)} = \\frac{2 x_C p_C^{(t)} p_I^{(t)}}{(p_C^{(t)})^2 + 2p_C^{(t)} p_I^{(t)} + 2p_C^{(t)} p_T^{(t)}}$$\n",
    "\n",
    "and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: E-step\n",
    "\n",
    "Code the expectation step for the latent genotype counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number in each phenotype\n",
    "x_C = 85  \n",
    "x_I = 196 \n",
    "x_T = 341\n",
    "\n",
    "N = x_C + x_I + x_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the values of the allele frequencies, we need to maximize the multinomial (log) likelihood.\n",
    "\n",
    "Since the combinatorial term does not involve $\\mathbf{p}$, we can write:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "Q(\\mathbf{p}) &\\propto x_{(CC)}^{(t)} \\log[(p_C^2)^{(t)}] + x_{(CI)}^{(t)} \\log[2p_C^{(t)}p_I^{(t)}] \\\\\n",
    "&+ x_{(CT)}^{(t)} \\log[2p_C^{(t)}p_T^{(t)}] + x_{(II)}^{(t)} \\log[(p_I^2)^{(t)}] \\\\\n",
    "&+ x_{(IT)}^{(t)} \\log[2p_I^{(t)}p_T^{(t)}] + x_{(TT)}^{(t)} \\log[(p_T^2)^{(t)}]\n",
    "\\end{aligned}$$\n",
    "\n",
    "Since $p_T = 1 - p_I + p_C$, we only need to worry about maximizing two functions:\n",
    "\n",
    "$$\\frac{dQ}{dp_C} = \\frac{2x_{(CC)}^{(t)} + x_{(CI)}^{(t)} + x_{(CT)}^{(t)}}{p_C} - \\frac{2x_{(TT)}^{(t)} + x_{(CT)}^{(t)} + x_{(IT)}^{(t)}}{1 - p_C - p_I}$$\n",
    "\n",
    "$$\\frac{dQ}{dp_I} = \\frac{2x_{(II)}^{(t)} + x_{(CI)}^{(t)} + x_{(IT)}^{(t)}}{p_I} - \\frac{2x_{(TT)}^{(t)} + x_{(CT)}^{(t)} + x_{(IT)}^{(t)}}{1 - p_C - p_I}$$\n",
    "\n",
    "If we set these equal to zero and solve for the $p$'s, we complete the M step.\n",
    "\n",
    "$$p_C^{(t+1)} = \\frac{2x_{(CC)}^{(t)} + x_{(CI)}^{(t)} + x_{(CT)}^{(t)}}{2N}$$\n",
    "\n",
    "$$p_I^{(t+1)} = \\frac{2x_{(II)}^{(t)} + x_{(CI)}^{(t)} + x_{(IT)}^{(t)}}{2N}$$\n",
    "\n",
    "$$p_T^{(t+1)} = \\frac{2x_{(TT)}^{(t)} + x_{(CT)}^{(t)} + x_{(IT)}^{(t)}}{2N}$$\n",
    "\n",
    "So, the update involves setting each $p$ equal to the phenotype frequencies that correspond to the latent genotype count at that step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: M-step\n",
    "\n",
    "Code a function for calculating the M-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Estimate allele frequencies\n",
    "\n",
    "Combine the E-step and M-step to estimate the latent allele frequencies using EM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence\n",
    "\n",
    "Each time we perform the maximization step, the likelihood of the observed data increases. Note that:\n",
    "\n",
    "$$P(x,z) = P(z \\,|\\, x)P(x)$$\n",
    "\n",
    "which implies:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "E[\\log P(x)| x, \\theta^{(t)}] &= E[\\log P(x,z)|\\theta^{(t)})] - E[\\log P(z \\,|\\, x)| x, \\theta^{(t)}] \\\\\n",
    "&= Q(\\theta | \\theta^{(t)}) - H(\\theta | \\theta^{(t)})\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $H(\\theta | \\theta^{(t)}) = E[\\log P(z \\,|\\, x)| x, \\theta^{(t)}]$.\n",
    "\n",
    "The second term is maximized with respect to $\\theta$ when $\\theta^{(t)} = \\theta$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "H(\\theta^{(t)} | \\theta^{(t)}) - H(\\theta | \\theta^{(t)}) &= E[\\log P(z \\,|\\, x, \\theta^{(t)}) - \\log P(z \\,|\\, x, \\theta) | x, \\theta^{(t)}] \\\\\n",
    "&= \\int -\\log \\left[ \\frac{\\log P(z \\,|\\, x, \\theta)}{\\log P(z \\,|\\, x, \\theta^{(t)})} \\right] \\log P(z \\,|\\, x, \\theta^{(t)}) dz \\\\\n",
    "&\\ge -\\log \\int \\log P(z \\,|\\, x, \\theta) dz = 0\n",
    "\\end{aligned}$$\n",
    "\n",
    "where the inequality is due to Jensen's inequality.\n",
    "\n",
    "So, any $\\theta \\ne \\theta^{(t)}$ makes $H(\\theta | \\theta^{(t)})$ smaller than $H(\\theta^{(t)} | \\theta^{(t)})$.\n",
    "\n",
    "If we choose a $\\theta^{(t+1)}$ to maximimze $Q(\\theta | \\theta^{(t)})$ then we have:\n",
    "\n",
    "$$\\log P(x |\\theta^{(t+1)}) - \\log P(x |\\theta^{(t)}) \\ge 0$$\n",
    "\n",
    "because $Q$ increases and $H$ decreases.\n",
    "\n",
    "The EM algorithm guaranteees that $P(x \\,|\\, \\theta^{(t+1)}) \\ge  P(x \\,|\\,  \\theta^{(t)})$, however there is no guarantee that we will obtain the true MLE (due to multimodality).\n",
    "\n",
    "### Order of convergence\n",
    "\n",
    "The global rate of convergence for EM is:\n",
    "\n",
    "$$\\rho = \\lim_{t \\rightarrow \\infty} \\frac{||\\theta^{(t+1)} - \\hat{\\theta}||}{||\\theta^{(t)} - \\hat{\\theta}||}$$\n",
    "\n",
    "EM has approximately linear convergence, provided the observed information is positive definite. The realized rate of convergence slows as the proportion of missing data increases.\n",
    "\n",
    "Though the performance of EM is very slow relative to other optimization methods, it is easy to implement and stable, and is therefore widely used. It works best for likelihoods of the [exponential family of distributions](https://en.wikipedia.org/wiki/Exponential_family)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Monitoring convergence\n",
    "\n",
    "Modify your EM code above to track the convergence of the algorithm as it is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- A. P. Dempster; N. M. Laird; D. B. Rubin. 1977. [Maximum Likelihood from Incomplete Data via the EM Algorithm](http://web.mit.edu/6.435/www/Dempster77.pdf) Journal of the Royal Statistical Society. Series B (Methodological), Vol. 39, No. 1. (1977), pp. 1-38.\n",
    "- [Python for Signal Processing](http://python-for-signal-processing.blogspot.com/2012/11/expectation-maximization-expectation.html)\n",
    "- [Stanford University's Machine Learning (Coursera)](https://www.coursera.org/course/ml)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": "3",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
